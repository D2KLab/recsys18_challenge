{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import filereader\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import html\n",
    "from functools import reduce\n",
    "from nltk.corpus import stopwords\n",
    "import numbers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_scaler(X:np.ndarray) -> np.ndarray:\n",
    "    X_scaled = QuantileTransformer().fit_transform(X)\n",
    "    X_scaled = MinMaxScaler(feature_range=[-1,1]).fit_transform(X_scaled)\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse lyrics to segment-line-structure, assuming lines are separated by line_border_indicator and\n",
    "# segments are separated by multiple consecutive line_border_indicator occurences\n",
    "# assuming line_border_indicator is <br> (standard in lyrics.wikia.com)\n",
    "def tree_structure(text):\n",
    "    #normalize segment border encoding\n",
    "    segment_border_encoder = '<segmentborder>'\n",
    "    line_border_encoder = '<lineborder>'\n",
    "    tree_string = re.sub('(( )*<br>( )*){2,}', segment_border_encoder, text)\n",
    "    tree_string = re.sub('( )*<br>( )*', line_border_encoder, tree_string)\n",
    "    #parse tree_string\n",
    "    segment_structure = tree_string.split(segment_border_encoder)\n",
    "    tree_structure = list(map(lambda segment: segment.split(line_border_encoder), segment_structure))\n",
    "    return tree_structure\n",
    "\n",
    "#flattened tree structure, does not differentiate between segment and line border\n",
    "def line_structure(lyric_tree):\n",
    "    return reduce(lambda x, segment: x + segment, lyric_tree, [])\n",
    "\n",
    "# flattened line_structure\n",
    "def token_structure(lyric_tree, tokenizer=word_tokenize):\n",
    "    return reduce(lambda x, line: extend_with_return(x, tokenizer(line)), line_structure(lyric_tree), [])\n",
    "\n",
    "def extend_with_return(some_list, other_list):\n",
    "    some_list.extend(other_list)\n",
    "    return some_list\n",
    "\n",
    "def normalize_lyric(lyric):\n",
    "    lyric = html.unescape(lyric)\n",
    "    lyric = lyric.lower()\n",
    "    return lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_document(document: list, parser):\n",
    "    parsed_sentences = []\n",
    "    for sentence in document:\n",
    "        parsed_sentences.extend(parser(sentence))\n",
    "    return parsed_sentences\n",
    "\n",
    "def doc_to_dict(doc: list, parser) -> dict:    \n",
    "    d = dict()\n",
    "    doc_triples = parse_document(doc, parser)\n",
    "    for rel in doc_triples:\n",
    "        d[rel] = d[rel] + 1 if rel in d else 1\n",
    "    return d\n",
    "\n",
    "def document_to_dictionary(doc_atoms: list) -> dict:\n",
    "    d = dict()\n",
    "    for atom in doc_atoms:\n",
    "        d[atom] = d[atom] + 1 if atom in d else 1\n",
    "    return d\n",
    "\n",
    "def documents_to_dictionaries(documents: list, min_doc_freq=1, max_doc_freq=1., limit=None) -> list:\n",
    "    dicts = []\n",
    "    atom_doc_freq = {}\n",
    "    n_doc = len(documents)\n",
    "    i = 0\n",
    "    for doc_atoms in documents:\n",
    "        d = dict()\n",
    "        for atom in doc_atoms:\n",
    "            d[atom] = d[atom] + 1 if atom in d else 1\n",
    "        dicts.append(d)\n",
    "        # increase doc_freq for atoms\n",
    "        for atom in d.keys():\n",
    "            atom_doc_freq[atom] = atom_doc_freq[atom] + 1 if atom in atom_doc_freq else 1\n",
    "        if i % 10000 == 0:\n",
    "            print('Progress: ' + str(round(i / n_doc * 100, 1)) + ' % of a total ' + str(n_doc))\n",
    "        i += 1\n",
    "    \n",
    "    # from CountVectorizer\n",
    "    max_doc_count = (max_doc_freq if isinstance(max_doc_freq, numbers.Integral) else max_doc_freq * n_doc)\n",
    "    min_doc_count = (min_doc_freq if isinstance(min_doc_freq, numbers.Integral) else min_doc_freq * n_doc)\n",
    "    mask = lambda item: min_doc_count <= atom_doc_freq[item[0]] <= max_doc_count\n",
    "    dicts = list(map(lambda x: filter_dict(x, mask), dicts))\n",
    "    \n",
    "    if not limit is None:\n",
    "        min_doc_count = sorted(atom_doc_freq.values(), reverse=True)[limit - 1] if len(atom_doc_freq) >= limit else min_doc_count\n",
    "        mask2 = lambda item: min_doc_count <= atom_doc_freq[item[0]]\n",
    "        dicts = list(map(lambda x: filter_dict(x, mask2), dicts))\n",
    "    return dicts\n",
    "\n",
    "def filter_dict(d: dict, item_property) -> dict:\n",
    "    d_filtered = dict()\n",
    "    for item in d.items():\n",
    "        if item_property(item):\n",
    "            d_filtered[item[0]] = item[1]\n",
    "    return d_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total song count: 367229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>spotify_track_uri</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>urlSong</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>langdetect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416116</th>\n",
       "      <td>416116</td>\n",
       "      <td>71zm5sWvDc3222XEvCvkXF</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>Rowdy Rowdy</td>\n",
       "      <td>http://lyrics.wikia.com/50_Cent:Rowdy_Rowdy</td>\n",
       "      <td>[50 Cent]&lt;br&gt;Yo LA niggaz are the rowdy niggaz...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416117</th>\n",
       "      <td>416117</td>\n",
       "      <td>6xGPZJmMpwLc6XcOGFygzd</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>The Enforcer</td>\n",
       "      <td>http://lyrics.wikia.com/50_Cent:The_Enforcer</td>\n",
       "      <td>Who wanna play with the enforcer?&lt;br&gt;Who wanna...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416118</th>\n",
       "      <td>416118</td>\n",
       "      <td>6bxvZDiuXOAwz5Fgb2a2Je</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>Wait Until Tonight</td>\n",
       "      <td>http://lyrics.wikia.com/50_Cent:Wait_Until_Ton...</td>\n",
       "      <td>If you think you&amp;apos;re lonely now&lt;br&gt;Wait un...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416119</th>\n",
       "      <td>416119</td>\n",
       "      <td>6fGjvkhTXsV5II8ynoSSfG</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>When It Rains It Pours</td>\n",
       "      <td>http://lyrics.wikia.com/50_Cent:When_It_Rains_...</td>\n",
       "      <td>Intro]&lt;br&gt;Yeah..&lt;br&gt;Its 50&lt;br&gt;One shot, One ki...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416120</th>\n",
       "      <td>416120</td>\n",
       "      <td>590LENpdOHTNGyYaytpy4S</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>You Should Be Here</td>\n",
       "      <td>http://lyrics.wikia.com/50_Cent:You_Should_Be_...</td>\n",
       "      <td>DJ Whoo Kid:Yea (?) Lloyd Banks 50 Cent G-Unit...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0       spotify_track_uri   artist                   title  \\\n",
       "416116      416116  71zm5sWvDc3222XEvCvkXF  50 Cent             Rowdy Rowdy   \n",
       "416117      416117  6xGPZJmMpwLc6XcOGFygzd  50 Cent            The Enforcer   \n",
       "416118      416118  6bxvZDiuXOAwz5Fgb2a2Je  50 Cent      Wait Until Tonight   \n",
       "416119      416119  6fGjvkhTXsV5II8ynoSSfG  50 Cent  When It Rains It Pours   \n",
       "416120      416120  590LENpdOHTNGyYaytpy4S  50 Cent      You Should Be Here   \n",
       "\n",
       "                                                  urlSong  \\\n",
       "416116        http://lyrics.wikia.com/50_Cent:Rowdy_Rowdy   \n",
       "416117       http://lyrics.wikia.com/50_Cent:The_Enforcer   \n",
       "416118  http://lyrics.wikia.com/50_Cent:Wait_Until_Ton...   \n",
       "416119  http://lyrics.wikia.com/50_Cent:When_It_Rains_...   \n",
       "416120  http://lyrics.wikia.com/50_Cent:You_Should_Be_...   \n",
       "\n",
       "                                                   lyrics langdetect  \n",
       "416116  [50 Cent]<br>Yo LA niggaz are the rowdy niggaz...         en  \n",
       "416117  Who wanna play with the enforcer?<br>Who wanna...         en  \n",
       "416118  If you think you&apos;re lonely now<br>Wait un...         en  \n",
       "416119  Intro]<br>Yeah..<br>Its 50<br>One shot, One ki...         en  \n",
       "416120  DJ Whoo Kid:Yea (?) Lloyd Banks 50 Cent G-Unit...         en  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpd = pd.read_csv('../resources/recsys_challenge_2018/mpd_wasabi_aligned_langdetect.csv', sep='\\t', encoding='utf-8')\n",
    "mpd = mpd[mpd['langdetect'] == 'en']\n",
    "print('Total song count:', len(mpd))\n",
    "mpd.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_lyrics = list(map(line_structure,\\\n",
    "                  map(tree_structure,\\\n",
    "                  map(normalize_lyric,\\\n",
    "                      mpd['lyrics'].values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.3 % of a total 367229\n",
      "Progress: 0.5 % of a total 367229\n",
      "Progress: 0.8 % of a total 367229\n",
      "Progress: 1.1 % of a total 367229\n",
      "Progress: 1.4 % of a total 367229\n",
      "Progress: 1.6 % of a total 367229\n",
      "Progress: 1.9 % of a total 367229\n",
      "Progress: 2.2 % of a total 367229\n",
      "Progress: 2.5 % of a total 367229\n",
      "Progress: 2.7 % of a total 367229\n",
      "Progress: 3.0 % of a total 367229\n",
      "Progress: 3.3 % of a total 367229\n",
      "Progress: 3.5 % of a total 367229\n",
      "Progress: 3.8 % of a total 367229\n",
      "Progress: 4.1 % of a total 367229\n",
      "Progress: 4.4 % of a total 367229\n",
      "Progress: 4.6 % of a total 367229\n",
      "Progress: 4.9 % of a total 367229\n",
      "Progress: 5.2 % of a total 367229\n",
      "Progress: 5.4 % of a total 367229\n",
      "Progress: 5.7 % of a total 367229\n",
      "Progress: 6.0 % of a total 367229\n",
      "Progress: 6.3 % of a total 367229\n",
      "Progress: 6.5 % of a total 367229\n",
      "Progress: 6.8 % of a total 367229\n",
      "Progress: 7.1 % of a total 367229\n",
      "Progress: 7.4 % of a total 367229\n",
      "Progress: 7.6 % of a total 367229\n",
      "Progress: 7.9 % of a total 367229\n",
      "Progress: 8.2 % of a total 367229\n",
      "Progress: 8.4 % of a total 367229\n",
      "Progress: 8.7 % of a total 367229\n",
      "Progress: 9.0 % of a total 367229\n",
      "Progress: 9.3 % of a total 367229\n",
      "Progress: 9.5 % of a total 367229\n",
      "Progress: 9.8 % of a total 367229\n",
      "Progress: 10.1 % of a total 367229\n",
      "Progress: 10.3 % of a total 367229\n",
      "Progress: 10.6 % of a total 367229\n",
      "Progress: 10.9 % of a total 367229\n",
      "Progress: 11.2 % of a total 367229\n",
      "Progress: 11.4 % of a total 367229\n",
      "Progress: 11.7 % of a total 367229\n",
      "Progress: 12.0 % of a total 367229\n",
      "Progress: 12.3 % of a total 367229\n",
      "Progress: 12.5 % of a total 367229\n",
      "Progress: 12.8 % of a total 367229\n",
      "Progress: 13.1 % of a total 367229\n",
      "Progress: 13.3 % of a total 367229\n",
      "Progress: 13.6 % of a total 367229\n",
      "Progress: 13.9 % of a total 367229\n",
      "Progress: 14.2 % of a total 367229\n",
      "Progress: 14.4 % of a total 367229\n",
      "Progress: 14.7 % of a total 367229\n",
      "Progress: 15.0 % of a total 367229\n",
      "Progress: 15.2 % of a total 367229\n",
      "Progress: 15.5 % of a total 367229\n",
      "Progress: 15.8 % of a total 367229\n",
      "Progress: 16.1 % of a total 367229\n",
      "Progress: 16.3 % of a total 367229\n",
      "Progress: 16.6 % of a total 367229\n",
      "Progress: 16.9 % of a total 367229\n",
      "Progress: 17.2 % of a total 367229\n",
      "Progress: 17.4 % of a total 367229\n",
      "Progress: 17.7 % of a total 367229\n",
      "Progress: 18.0 % of a total 367229\n",
      "Progress: 18.2 % of a total 367229\n",
      "Progress: 18.5 % of a total 367229\n",
      "Progress: 18.8 % of a total 367229\n",
      "Progress: 19.1 % of a total 367229\n",
      "Progress: 19.3 % of a total 367229\n",
      "Progress: 19.6 % of a total 367229\n",
      "Progress: 19.9 % of a total 367229\n",
      "Progress: 20.2 % of a total 367229\n",
      "Progress: 20.4 % of a total 367229\n",
      "Progress: 20.7 % of a total 367229\n",
      "Progress: 21.0 % of a total 367229\n",
      "Progress: 21.2 % of a total 367229\n",
      "Progress: 21.5 % of a total 367229\n",
      "Progress: 21.8 % of a total 367229\n",
      "Progress: 22.1 % of a total 367229\n",
      "Progress: 22.3 % of a total 367229\n",
      "Progress: 22.6 % of a total 367229\n",
      "Progress: 22.9 % of a total 367229\n",
      "Progress: 23.1 % of a total 367229\n",
      "Progress: 23.4 % of a total 367229\n",
      "Progress: 23.7 % of a total 367229\n",
      "Progress: 24.0 % of a total 367229\n",
      "Progress: 24.2 % of a total 367229\n",
      "Progress: 24.5 % of a total 367229\n",
      "Progress: 24.8 % of a total 367229\n",
      "Progress: 25.1 % of a total 367229\n",
      "Progress: 25.3 % of a total 367229\n",
      "Progress: 25.6 % of a total 367229\n",
      "Progress: 25.9 % of a total 367229\n",
      "Progress: 26.1 % of a total 367229\n",
      "Progress: 26.4 % of a total 367229\n",
      "Progress: 26.7 % of a total 367229\n",
      "Progress: 27.0 % of a total 367229\n",
      "Progress: 27.2 % of a total 367229\n",
      "Progress: 27.5 % of a total 367229\n",
      "Progress: 27.8 % of a total 367229\n",
      "Progress: 28.0 % of a total 367229\n",
      "Progress: 28.3 % of a total 367229\n",
      "Progress: 28.6 % of a total 367229\n",
      "Progress: 28.9 % of a total 367229\n",
      "Progress: 29.1 % of a total 367229\n",
      "Progress: 29.4 % of a total 367229\n",
      "Progress: 29.7 % of a total 367229\n",
      "Progress: 30.0 % of a total 367229\n",
      "Progress: 30.2 % of a total 367229\n",
      "Progress: 30.5 % of a total 367229\n",
      "Progress: 30.8 % of a total 367229\n",
      "Progress: 31.0 % of a total 367229\n",
      "Progress: 31.3 % of a total 367229\n",
      "Progress: 31.6 % of a total 367229\n",
      "Progress: 31.9 % of a total 367229\n",
      "Progress: 32.1 % of a total 367229\n",
      "Progress: 32.4 % of a total 367229\n",
      "Progress: 32.7 % of a total 367229\n",
      "Progress: 32.9 % of a total 367229\n",
      "Progress: 33.2 % of a total 367229\n",
      "Progress: 33.5 % of a total 367229\n",
      "Progress: 33.8 % of a total 367229\n",
      "Progress: 34.0 % of a total 367229\n",
      "Progress: 34.3 % of a total 367229\n",
      "Progress: 34.6 % of a total 367229\n",
      "Progress: 34.9 % of a total 367229\n",
      "Progress: 35.1 % of a total 367229\n",
      "Progress: 35.4 % of a total 367229\n",
      "Progress: 35.7 % of a total 367229\n",
      "Progress: 35.9 % of a total 367229\n",
      "Progress: 36.2 % of a total 367229\n",
      "Progress: 36.5 % of a total 367229\n",
      "Progress: 36.8 % of a total 367229\n",
      "Progress: 37.0 % of a total 367229\n",
      "Progress: 37.3 % of a total 367229\n",
      "Progress: 37.6 % of a total 367229\n",
      "Progress: 37.9 % of a total 367229\n",
      "Progress: 38.1 % of a total 367229\n",
      "Progress: 38.4 % of a total 367229\n",
      "Progress: 38.7 % of a total 367229\n",
      "Progress: 38.9 % of a total 367229\n",
      "Progress: 39.2 % of a total 367229\n",
      "Progress: 39.5 % of a total 367229\n",
      "Progress: 39.8 % of a total 367229\n",
      "Progress: 40.0 % of a total 367229\n",
      "Progress: 40.3 % of a total 367229\n",
      "Progress: 40.6 % of a total 367229\n",
      "Progress: 40.8 % of a total 367229\n",
      "Progress: 41.1 % of a total 367229\n",
      "Progress: 41.4 % of a total 367229\n",
      "Progress: 41.7 % of a total 367229\n",
      "Progress: 41.9 % of a total 367229\n",
      "Progress: 42.2 % of a total 367229\n",
      "Progress: 42.5 % of a total 367229\n",
      "Progress: 42.8 % of a total 367229\n",
      "Progress: 43.0 % of a total 367229\n",
      "Progress: 43.3 % of a total 367229\n",
      "Progress: 43.6 % of a total 367229\n",
      "Progress: 43.8 % of a total 367229\n",
      "Progress: 44.1 % of a total 367229\n",
      "Progress: 44.4 % of a total 367229\n",
      "Progress: 44.7 % of a total 367229\n",
      "Progress: 44.9 % of a total 367229\n",
      "Progress: 45.2 % of a total 367229\n",
      "Progress: 45.5 % of a total 367229\n",
      "Progress: 45.7 % of a total 367229\n",
      "Progress: 46.0 % of a total 367229\n",
      "Progress: 46.3 % of a total 367229\n",
      "Progress: 46.6 % of a total 367229\n",
      "Progress: 46.8 % of a total 367229\n",
      "Progress: 47.1 % of a total 367229\n",
      "Progress: 47.4 % of a total 367229\n",
      "Progress: 47.7 % of a total 367229\n",
      "Progress: 47.9 % of a total 367229\n",
      "Progress: 48.2 % of a total 367229\n",
      "Progress: 48.5 % of a total 367229\n",
      "Progress: 48.7 % of a total 367229\n",
      "Progress: 49.0 % of a total 367229\n",
      "Progress: 49.3 % of a total 367229\n",
      "Progress: 49.6 % of a total 367229\n",
      "Progress: 49.8 % of a total 367229\n",
      "Progress: 50.1 % of a total 367229\n",
      "Progress: 50.4 % of a total 367229\n",
      "Progress: 50.6 % of a total 367229\n",
      "Progress: 50.9 % of a total 367229\n",
      "Progress: 51.2 % of a total 367229\n",
      "Progress: 51.5 % of a total 367229\n",
      "Progress: 51.7 % of a total 367229\n",
      "Progress: 52.0 % of a total 367229\n",
      "Progress: 52.3 % of a total 367229\n",
      "Progress: 52.6 % of a total 367229\n",
      "Progress: 52.8 % of a total 367229\n",
      "Progress: 53.1 % of a total 367229\n",
      "Progress: 53.4 % of a total 367229\n",
      "Progress: 53.6 % of a total 367229\n",
      "Progress: 53.9 % of a total 367229\n",
      "Progress: 54.2 % of a total 367229\n",
      "Progress: 54.5 % of a total 367229\n",
      "Progress: 54.7 % of a total 367229\n",
      "Progress: 55.0 % of a total 367229\n",
      "Progress: 55.3 % of a total 367229\n",
      "Progress: 55.6 % of a total 367229\n",
      "Progress: 55.8 % of a total 367229\n",
      "Progress: 56.1 % of a total 367229\n",
      "Progress: 56.4 % of a total 367229\n",
      "Progress: 56.6 % of a total 367229\n",
      "Progress: 56.9 % of a total 367229\n",
      "Progress: 57.2 % of a total 367229\n",
      "Progress: 57.5 % of a total 367229\n",
      "Progress: 57.7 % of a total 367229\n",
      "Progress: 58.0 % of a total 367229\n",
      "Progress: 58.3 % of a total 367229\n",
      "Progress: 58.5 % of a total 367229\n",
      "Progress: 58.8 % of a total 367229\n",
      "Progress: 59.1 % of a total 367229\n",
      "Progress: 59.4 % of a total 367229\n",
      "Progress: 59.6 % of a total 367229\n",
      "Progress: 59.9 % of a total 367229\n",
      "Progress: 60.2 % of a total 367229\n",
      "Progress: 60.5 % of a total 367229\n",
      "Progress: 60.7 % of a total 367229\n",
      "Progress: 61.0 % of a total 367229\n",
      "Progress: 61.3 % of a total 367229\n",
      "Progress: 61.5 % of a total 367229\n",
      "Progress: 61.8 % of a total 367229\n",
      "Progress: 62.1 % of a total 367229\n",
      "Progress: 62.4 % of a total 367229\n",
      "Progress: 62.6 % of a total 367229\n",
      "Progress: 62.9 % of a total 367229\n",
      "Progress: 63.2 % of a total 367229\n",
      "Progress: 63.4 % of a total 367229\n",
      "Progress: 63.7 % of a total 367229\n",
      "Progress: 64.0 % of a total 367229\n",
      "Progress: 64.3 % of a total 367229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 64.5 % of a total 367229\n",
      "Progress: 64.8 % of a total 367229\n",
      "Progress: 65.1 % of a total 367229\n",
      "Progress: 65.4 % of a total 367229\n",
      "Progress: 65.6 % of a total 367229\n",
      "Progress: 65.9 % of a total 367229\n",
      "Progress: 66.2 % of a total 367229\n",
      "Progress: 66.4 % of a total 367229\n",
      "Progress: 66.7 % of a total 367229\n",
      "Progress: 67.0 % of a total 367229\n",
      "Progress: 67.3 % of a total 367229\n",
      "Progress: 67.5 % of a total 367229\n",
      "Progress: 67.8 % of a total 367229\n",
      "Progress: 68.1 % of a total 367229\n",
      "Progress: 68.3 % of a total 367229\n",
      "Progress: 68.6 % of a total 367229\n",
      "Progress: 68.9 % of a total 367229\n",
      "Progress: 69.2 % of a total 367229\n",
      "Progress: 69.4 % of a total 367229\n",
      "Progress: 69.7 % of a total 367229\n",
      "Progress: 70.0 % of a total 367229\n",
      "Progress: 70.3 % of a total 367229\n",
      "Progress: 70.5 % of a total 367229\n",
      "Progress: 70.8 % of a total 367229\n",
      "Progress: 71.1 % of a total 367229\n",
      "Progress: 71.3 % of a total 367229\n",
      "Progress: 71.6 % of a total 367229\n",
      "Progress: 71.9 % of a total 367229\n",
      "Progress: 72.2 % of a total 367229\n",
      "Progress: 72.4 % of a total 367229\n",
      "Progress: 72.7 % of a total 367229\n",
      "Progress: 73.0 % of a total 367229\n",
      "Progress: 73.3 % of a total 367229\n",
      "Progress: 73.5 % of a total 367229\n",
      "Progress: 73.8 % of a total 367229\n",
      "Progress: 74.1 % of a total 367229\n",
      "Progress: 74.3 % of a total 367229\n",
      "Progress: 74.6 % of a total 367229\n",
      "Progress: 74.9 % of a total 367229\n",
      "Progress: 75.2 % of a total 367229\n",
      "Progress: 75.4 % of a total 367229\n",
      "Progress: 75.7 % of a total 367229\n",
      "Progress: 76.0 % of a total 367229\n",
      "Progress: 76.2 % of a total 367229\n",
      "Progress: 76.5 % of a total 367229\n",
      "Progress: 76.8 % of a total 367229\n",
      "Progress: 77.1 % of a total 367229\n",
      "Progress: 77.3 % of a total 367229\n",
      "Progress: 77.6 % of a total 367229\n",
      "Progress: 77.9 % of a total 367229\n",
      "Progress: 78.2 % of a total 367229\n",
      "Progress: 78.4 % of a total 367229\n",
      "Progress: 78.7 % of a total 367229\n",
      "Progress: 79.0 % of a total 367229\n",
      "Progress: 79.2 % of a total 367229\n",
      "Progress: 79.5 % of a total 367229\n",
      "Progress: 79.8 % of a total 367229\n",
      "Progress: 80.1 % of a total 367229\n",
      "Progress: 80.3 % of a total 367229\n",
      "Progress: 80.6 % of a total 367229\n",
      "Progress: 80.9 % of a total 367229\n",
      "Progress: 81.1 % of a total 367229\n",
      "Progress: 81.4 % of a total 367229\n",
      "Progress: 81.7 % of a total 367229\n",
      "Progress: 82.0 % of a total 367229\n",
      "Progress: 82.2 % of a total 367229\n",
      "Progress: 82.5 % of a total 367229\n",
      "Progress: 82.8 % of a total 367229\n",
      "Progress: 83.1 % of a total 367229\n",
      "Progress: 83.3 % of a total 367229\n",
      "Progress: 83.6 % of a total 367229\n",
      "Progress: 83.9 % of a total 367229\n",
      "Progress: 84.1 % of a total 367229\n",
      "Progress: 84.4 % of a total 367229\n",
      "Progress: 84.7 % of a total 367229\n",
      "Progress: 85.0 % of a total 367229\n",
      "Progress: 85.2 % of a total 367229\n",
      "Progress: 85.5 % of a total 367229\n",
      "Progress: 85.8 % of a total 367229\n",
      "Progress: 86.0 % of a total 367229\n",
      "Progress: 86.3 % of a total 367229\n",
      "Progress: 86.6 % of a total 367229\n",
      "Progress: 86.9 % of a total 367229\n",
      "Progress: 87.1 % of a total 367229\n",
      "Progress: 87.4 % of a total 367229\n",
      "Progress: 87.7 % of a total 367229\n",
      "Progress: 88.0 % of a total 367229\n",
      "Progress: 88.2 % of a total 367229\n",
      "Progress: 88.5 % of a total 367229\n",
      "Progress: 88.8 % of a total 367229\n",
      "Progress: 89.0 % of a total 367229\n",
      "Progress: 89.3 % of a total 367229\n",
      "Progress: 89.6 % of a total 367229\n",
      "Progress: 89.9 % of a total 367229\n",
      "Progress: 90.1 % of a total 367229\n",
      "Progress: 90.4 % of a total 367229\n",
      "Progress: 90.7 % of a total 367229\n",
      "Progress: 91.0 % of a total 367229\n",
      "Progress: 91.2 % of a total 367229\n",
      "Progress: 91.5 % of a total 367229\n",
      "Progress: 91.8 % of a total 367229\n",
      "Progress: 92.0 % of a total 367229\n",
      "Progress: 92.3 % of a total 367229\n",
      "Progress: 92.6 % of a total 367229\n",
      "Progress: 92.9 % of a total 367229\n",
      "Progress: 93.1 % of a total 367229\n",
      "Progress: 93.4 % of a total 367229\n",
      "Progress: 93.7 % of a total 367229\n",
      "Progress: 93.9 % of a total 367229\n",
      "Progress: 94.2 % of a total 367229\n",
      "Progress: 94.5 % of a total 367229\n",
      "Progress: 94.8 % of a total 367229\n",
      "Progress: 95.0 % of a total 367229\n",
      "Progress: 95.3 % of a total 367229\n",
      "Progress: 95.6 % of a total 367229\n",
      "Progress: 95.9 % of a total 367229\n",
      "Progress: 96.1 % of a total 367229\n",
      "Progress: 96.4 % of a total 367229\n",
      "Progress: 96.7 % of a total 367229\n",
      "Progress: 96.9 % of a total 367229\n",
      "Progress: 97.2 % of a total 367229\n",
      "Progress: 97.5 % of a total 367229\n",
      "Progress: 97.8 % of a total 367229\n",
      "Progress: 98.0 % of a total 367229\n",
      "Progress: 98.3 % of a total 367229\n",
      "Progress: 98.6 % of a total 367229\n",
      "Progress: 98.8 % of a total 367229\n",
      "Progress: 99.1 % of a total 367229\n",
      "Progress: 99.4 % of a total 367229\n",
      "Progress: 99.7 % of a total 367229\n",
      "Progress: 99.9 % of a total 367229\n"
     ]
    }
   ],
   "source": [
    "#stopwords_set = set(stopwords.words('english'))\n",
    "documents_as_atoms = []\n",
    "i = 0\n",
    "for lyric in all_lyrics:\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print('Progress:', round(i/len(all_lyrics)*100, 1), '% of a total', len(all_lyrics))\n",
    "    lyric_atoms = []\n",
    "    for line in lyric:\n",
    "        tokenized_line = word_tokenize(line)\n",
    "        #tokenized_line = [word for word in tokenized_line if word not in stopwords_set]\n",
    "        # add parsing step here\n",
    "        lyric_atoms.extend(tokenized_line)\n",
    "    documents_as_atoms.append(lyric_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367229"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_as_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.0 % of a total 367229\n",
      "Progress: 2.7 % of a total 367229\n",
      "Progress: 5.4 % of a total 367229\n",
      "Progress: 8.2 % of a total 367229\n",
      "Progress: 10.9 % of a total 367229\n",
      "Progress: 13.6 % of a total 367229\n",
      "Progress: 16.3 % of a total 367229\n",
      "Progress: 19.1 % of a total 367229\n",
      "Progress: 21.8 % of a total 367229\n",
      "Progress: 24.5 % of a total 367229\n",
      "Progress: 27.2 % of a total 367229\n",
      "Progress: 30.0 % of a total 367229\n",
      "Progress: 32.7 % of a total 367229\n",
      "Progress: 35.4 % of a total 367229\n",
      "Progress: 38.1 % of a total 367229\n",
      "Progress: 40.8 % of a total 367229\n",
      "Progress: 43.6 % of a total 367229\n",
      "Progress: 46.3 % of a total 367229\n",
      "Progress: 49.0 % of a total 367229\n",
      "Progress: 51.7 % of a total 367229\n",
      "Progress: 54.5 % of a total 367229\n",
      "Progress: 57.2 % of a total 367229\n",
      "Progress: 59.9 % of a total 367229\n",
      "Progress: 62.6 % of a total 367229\n",
      "Progress: 65.4 % of a total 367229\n",
      "Progress: 68.1 % of a total 367229\n",
      "Progress: 70.8 % of a total 367229\n",
      "Progress: 73.5 % of a total 367229\n",
      "Progress: 76.2 % of a total 367229\n",
      "Progress: 79.0 % of a total 367229\n",
      "Progress: 81.7 % of a total 367229\n",
      "Progress: 84.4 % of a total 367229\n",
      "Progress: 87.1 % of a total 367229\n",
      "Progress: 89.9 % of a total 367229\n",
      "Progress: 92.6 % of a total 367229\n",
      "Progress: 95.3 % of a total 367229\n",
      "Progress: 98.0 % of a total 367229\n",
      "(367229, 6003)\n"
     ]
    }
   ],
   "source": [
    "# parameters are comparable to those in sklearn's CountVectorizer\n",
    "atom_dictionaries = documents_to_dictionaries(documents_as_atoms, min_doc_freq=2, max_doc_freq=0.95, limit=6000)\n",
    "\n",
    "atom_dictionaries_train = atom_dictionaries\n",
    "\n",
    "dvect = DictVectorizer()\n",
    "X_train = dvect.fit_transform(atom_dictionaries_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LDA models with tf features, n_samples=367229 and n_features=6003...\n",
      "done in 29917.949s.\n",
      "\n",
      "Perplexity: 336.4649236484019\n",
      "Score     : -558654639.4800696\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: ’ i s t m it you don re ll can my ve that ‘ know but d won me\n",
      "Topic #1: dead head alive wake inside hate fucking face sick killing up tired waste brain enemy troubles awake wasted bury grave\n",
      "Topic #2: up get the out it to and off on down now in make take this beat stop so put 'em\n",
      "Topic #3: rock play hear music roll sound soul listen oooh loud rhythm guitar playing 'n bass louder crush lion ow hardest\n",
      "Topic #4: be if could would should must or might rather free hero have used fine world meet careful by string honest\n",
      "Topic #5: n't do ca wo no ai know i you but just stop what care say 'cause it if why get\n",
      "Topic #6: heaven hope rise carry angel peace shall earth grace welcome angels faith above strong cross mother wings prayer thee father\n",
      "Topic #7: i my 'm me and am know can in when see but not with so 'll that feel 'cause myself\n",
      "Topic #8: come back home here ooh coming bring on to free now set take along again paradise heartbeat place door drum\n",
      "Topic #9: hang sign shadow golden longer mr. breaks seven sail spring california 'till island moves celebrate bay speaking naked longing foot\n",
      "Topic #10: , yes now no you well too three so 's oh it say ; the long please on miss honey\n",
      "Topic #11: ah bad dem mi a di de yuh boom fi nah man ay gal and jah dat nuh roses garden\n",
      "Topic #12: got yeah hey ta everybody now uh get say c'mon huh said well ohh oh right mmm man ahh some\n",
      "Topic #13: two thousand years four five count ten jump } { six fair saved lead hundred mystery queen nine green tree\n",
      "Topic #14: > < instrumental /i : b /b class= trebleclef.png href= /a title= http span style= /span src= img alt= height=\n",
      "Topic #15: ? what why do how who is where did can are does tell know say or this about you wonder\n",
      "Topic #16: new boy blue city mama pretty blues daddy country gim york america poor shoes step boogie american whiskey news law\n",
      "Topic #17: it 's that the and all is to what there not a just but time so when , like in\n",
      "Topic #18: the and a in on of got at with some money big for girls boys hot car my look go\n",
      "Topic #19: no is this one there more life for than nothing only live 's can not world all be without to\n",
      "Topic #20: he his the and a man 's to him in that but of with well on as who , when\n",
      "Topic #21: night the tonight right all dance light alright shine morning lights with dancing party wild bright tight last woah fun\n",
      "Topic #22: the of to in and is a from world with will that as this all by , life are through\n",
      "Topic #23: you 're your know and when can that see are with say do for if what so 'll to all\n",
      "Topic #24: a like little of just an in bit with for such lot dream fool or kind place have while thing\n",
      "Topic #25: she her 's and girl woman to that loves but a when lady with says knows said know wants as\n",
      "Topic #26: 'll will never again always ever forever fall be fire burn end friend until break soon promise and till take\n",
      "Topic #27: ] [ ya chorus : ready nobody x2 verse hook ... cause x4 jones thang x3 wha intro man shoulda\n",
      "Topic #28: ( ) ... it now yeah ha x2 say yes ooh you x4 2x x3 uh-huh stop i see 's\n",
      "Topic #29: ' 's goin ai nothin comin to tryin on the lookin lovin feelin n't livin gettin doin runnin somethin talkin\n",
      "Topic #30: old gold house grow ring doo dear sunshine born story stone silver rose hill bell wear bleeding chain raise diamond\n",
      "Topic #31: - move die shake whoa next cos texas later upside disco cha sooner thief san shove coz involved rush lone\n",
      "Topic #32: la da work send closer ba doctor revolution mad natural fix sake constant medicine invisible modern goodness harder noise alarm\n",
      "Topic #33: o watching sea mighty wave ocean voices ship west waves que brave east south y fighting shore north soldier el\n",
      "Topic #34: i was and the were that had it did said 'd could never but would when my now then knew\n",
      "Topic #35: your mind hands name body you put hand open take lay touch lips mouth ho head close taste hold soul\n",
      "Topic #36: 've been long over have done seen waiting gone before since has trouble heard too time taken awhile all now\n",
      "Topic #37: . , ; ... : this an not by to have l.a from because with that spoken fine great may\n",
      "Topic #38: : chorus its verse 2 im u & repeat 1 dont yea cuz aint 3 cant bridge thats cause 4\n",
      "Topic #39: me ... tell take please with my help leave make call show now give hold ha see honey free hand\n",
      "Topic #40: the and lord sing to song is jesus christmas god all of in holy king happy may singing glory praise\n",
      "Topic #41: let go show low where calling everywhere control wherever ahead flow begin blow breakdown ohhhh passion tight highs lows creep\n",
      "Topic #42: to want i need give all everything do just have what somebody someone anything else wanted something needs hold whatever\n",
      "Topic #43: away time day run every stay gone another from take wait far fly one tomorrow for running belong way walk\n",
      "Topic #44: na gon wan make be get take do just break lose tell change really whatcha live miss leave some cause\n",
      "Topic #45: love my heart in you and for is that with mine of true so arms lonely oh loving darling cry\n",
      "Topic #46: for god believe save stand hell war not living die lies lie death truth thank devil life pray evil power\n",
      "Topic #47: they and all the are them their people these to that who things those some but so 're many in\n",
      "Topic #48: the in and a to my 's there on out eyes like where when of as sun through with from\n",
      "Topic #49: on down the around keep way going and high ride hold turn side town road round ground to walk slow\n",
      "Topic #50: miles million babe build escape cover working bottom building crash lets paint confused monster guard ooooh stairs tearing sailing ease\n",
      "Topic #51: baby girl like you i so good me feel that make just the it oh crazy way about do sweet\n",
      "Topic #52: oh ! -- bang hoo woo oh-oh wow ohhh mon harry no ; neat hmmm gentlemen now laugh mark psycho\n",
      "Topic #53: we our us 're and are can together all this now here so when in hearts make know were have\n",
      "Topic #54: '' `` ? : a bye image 30 instrumental floating flipped flippin flipping flirt flo flowers float floatin florida flop\n",
      "Topic #55: i the a you my that like to and in with 'm n't on me shit nigga we fuck they\n",
      "Topic #56: i to the and you that but so it me just a of this all n't for 's not ,\n",
      "Topic #57: black blood kill white fight red pain train follow cut bleed gun scream tear teach blame yourself machine endless veins\n",
      "Topic #58: beautiful dirty wants weather dig deeper deny faster steps metal monkey pa twist riding lazy underneath imagine refuse wipe gate\n",
      "Topic #59: whole ok rules stick fools rule knife / tie rainbow attack tough rough pushing shade jungle gentle breakin tick summertime\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_features = X_train.shape[1]\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=60, max_iter=100,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0,\n",
    "                                n_jobs=1)\n",
    "t0 = time()\n",
    "X_train_lda = lda.fit_transform(X_train)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print('\\nPerplexity:', lda.perplexity(X_train))\n",
    "print('Score     :', lda.score(X_train))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = dvect.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 259.603s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "X_train_lda_scaled = custom_scaler(X_train_lda.T).T\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367229, 60)\n",
      "\n",
      "[5.06585613e-05 5.06585613e-05 5.06585613e-05 5.06585613e-05\n",
      " 5.06585613e-05 5.06585613e-05 5.06585613e-05 1.98706074e-01\n",
      " 5.06585613e-05 5.06585613e-05 4.94756343e-02 5.06585613e-05\n",
      " 5.47357133e-02 3.09017224e-03 5.06585613e-05 5.06585613e-05\n",
      " 5.06585613e-05 9.31727519e-02 5.06585613e-05 5.06585613e-05\n",
      " 5.06585613e-05 3.56382417e-02 3.31279043e-01 5.06585613e-05\n",
      " 5.06585613e-05 5.06585613e-05 5.06585613e-05 5.06585613e-05\n",
      " 5.06585613e-05 5.06585613e-05 5.06585613e-05 5.06585613e-05\n",
      " 5.06585613e-05 5.06585613e-05 5.06899647e-02 5.06585613e-05\n",
      " 5.06585613e-05 5.06585613e-05 5.06585613e-05 3.85559796e-02\n",
      " 5.06585613e-05 5.06585613e-05 5.06585613e-05 5.06585613e-05\n",
      " 5.06585613e-05 5.06585613e-05 5.06585613e-05 5.06585613e-05\n",
      " 5.06585613e-05 5.06585613e-05 5.06585613e-05 5.06585613e-05\n",
      " 5.06585613e-05 5.06585613e-05 5.06585613e-05 5.06585613e-05\n",
      " 1.42123497e-01 5.06585613e-05 5.06585613e-05 5.06585613e-05]\n",
      "\n",
      "[-1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.          0.96602643 -1.         -1.          0.79751859 -1.\n",
      "  0.86393949  0.69394914 -1.         -1.         -1.          0.89823241\n",
      " -1.         -1.         -1.          0.7295891   1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.          0.83009704 -1.\n",
      " -1.         -1.         -1.          0.76215114 -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.         -1.         -1.         -1.         -1.\n",
      " -1.         -1.          0.93217134 -1.         -1.         -1.        ]\n"
     ]
    }
   ],
   "source": [
    "# feature scaling example\n",
    "peek_document = 22\n",
    "print(X_train_lda.shape)\n",
    "print()\n",
    "print(X_train_lda[peek_document])\n",
    "print()\n",
    "print(X_train_lda_scaled[peek_document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "uris = mpd['spotify_track_uri'].values\n",
    "for i in range(len(mpd)):\n",
    "    d[uris[i]] = X_train_lda_scaled[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_best_topic(model, feature_names, n_top_words, best_topic_id):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        if topic_idx == best_topic_id:\n",
    "            message = \"Best Topic #%d: \" % topic_idx\n",
    "            message += \" \".join([feature_names[i]\n",
    "                                 for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "            print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #56: i to the and you that but so it me just a of this all n't for 's not ,\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['i admire your perseverance!',\n",
       "  'everytime my back is turned your falling closer into my world,',\n",
       "  \"i've told you so many times you need to back down, need to back down.\",\n",
       "  'i told you you need to walk away.',\n",
       "  'all the countless efforts i have made.',\n",
       "  \"one day i'll get you back, i swear i'll get you back.\",\n",
       "  'will this ever end or will time stand still forever?',\n",
       "  'will this ever end or will time stand still forever?',\n",
       "  \"everytime my back is turned you're falling closer to my world.\",\n",
       "  \"how can you sleep when you know what you're doing to me?\",\n",
       "  \"everytime my back is turned you're falling closer to my world.\",\n",
       "  \"how can you sleep when you know what you're doing to me?\",\n",
       "  'i told you you need to walk away',\n",
       "  'fuck all the efforts that i have made.',\n",
       "  \"i've got you right where i want you.\",\n",
       "  \"after all the years i've known you when did you decide to fuck this up?\",\n",
       "  \"after all the years i've known you when did you decide to try and fuck this up?\",\n",
       "  'i still admire your perseverance!',\n",
       "  \"how did you think you'd get away with this?!\",\n",
       "  \"and it's time to teach you a lesson that you're never gonna fucking forget!\",\n",
       "  'you are never gonna forget, not any time soon!',\n",
       "  \"you're never gonna forget me!\",\n",
       "  'brargh!']]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topic modelling example\n",
    "uri = list(d.keys())[1969]\n",
    "topics = d[uri]\n",
    "best_topic = np.argmax(topics)\n",
    "print_top(lda, tf_feature_names, 20, best_topic)\n",
    "print()\n",
    "tree_structure(normalize_lyric(mpd.loc[uri]['lyrics']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
