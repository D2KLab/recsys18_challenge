{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:02:30.725272Z",
     "start_time": "2018-05-23T15:02:16.372791Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "from functools import reduce\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import spacy\n",
    "import pronouncing\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:02:38.810822Z",
     "start_time": "2018-05-23T15:02:30.728953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_track_uri</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>urlSong</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6Z32g3TxhI9KOEDxkF5whx</td>\n",
       "      <td>A Broken Silence</td>\n",
       "      <td>What Are We Waiting For (Life Is Wonderful)</td>\n",
       "      <td>http://lyrics.wikia.com/A_Broken_Silence:What_...</td>\n",
       "      <td>(Cactus)&lt;br&gt;What are we waiting for? It&amp;apos;s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1fTNpl2mxqHVlLqRNbyDhR</td>\n",
       "      <td>A Day To Remember</td>\n",
       "      <td>I'm Made of Wax, Larry, What Are You Made Of?</td>\n",
       "      <td>http://lyrics.wikia.com/A_Day_To_Remember:I%27...</td>\n",
       "      <td>Don&amp;apos;t blink, they won&amp;apos;t even miss yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7BQk0o7TxM3WRFTPCuA4e4</td>\n",
       "      <td>A Fine Frenzy</td>\n",
       "      <td>Almost Lover (Live)</td>\n",
       "      <td>http://lyrics.wikia.com/A_Fine_Frenzy:Almost_L...</td>\n",
       "      <td>Your fingertips across my skin&lt;br&gt;The palm tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33VihH9UNQMxiQS4wcPIKL</td>\n",
       "      <td>A Flock Of Seagulls</td>\n",
       "      <td>I Ran</td>\n",
       "      <td>http://lyrics.wikia.com/A_Flock_Of_Seagulls:I_...</td>\n",
       "      <td>I walk along the avenue&lt;br&gt;I never thought I&amp;a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VNW7zhvsqo5UD0kUiRTYr</td>\n",
       "      <td>A Flock Of Seagulls</td>\n",
       "      <td>I Ran (So Far Away) (Re-Recorded / Remastered)</td>\n",
       "      <td>http://lyrics.wikia.com/A_Flock_Of_Seagulls:I_...</td>\n",
       "      <td>I walk along the avenue&lt;br&gt;I never thought I&amp;a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        spotify_track_uri               artist  \\\n",
       "0  6Z32g3TxhI9KOEDxkF5whx     A Broken Silence   \n",
       "1  1fTNpl2mxqHVlLqRNbyDhR    A Day To Remember   \n",
       "2  7BQk0o7TxM3WRFTPCuA4e4        A Fine Frenzy   \n",
       "3  33VihH9UNQMxiQS4wcPIKL  A Flock Of Seagulls   \n",
       "4  5VNW7zhvsqo5UD0kUiRTYr  A Flock Of Seagulls   \n",
       "\n",
       "                                            title  \\\n",
       "0     What Are We Waiting For (Life Is Wonderful)   \n",
       "1   I'm Made of Wax, Larry, What Are You Made Of?   \n",
       "2                             Almost Lover (Live)   \n",
       "3                                           I Ran   \n",
       "4  I Ran (So Far Away) (Re-Recorded / Remastered)   \n",
       "\n",
       "                                             urlSong  \\\n",
       "0  http://lyrics.wikia.com/A_Broken_Silence:What_...   \n",
       "1  http://lyrics.wikia.com/A_Day_To_Remember:I%27...   \n",
       "2  http://lyrics.wikia.com/A_Fine_Frenzy:Almost_L...   \n",
       "3  http://lyrics.wikia.com/A_Flock_Of_Seagulls:I_...   \n",
       "4  http://lyrics.wikia.com/A_Flock_Of_Seagulls:I_...   \n",
       "\n",
       "                                              lyrics  \n",
       "0  (Cactus)<br>What are we waiting for? It&apos;s...  \n",
       "1  Don&apos;t blink, they won&apos;t even miss yo...  \n",
       "2  Your fingertips across my skin<br>The palm tre...  \n",
       "3  I walk along the avenue<br>I never thought I&a...  \n",
       "4  I walk along the avenue<br>I never thought I&a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpd_with_lyrics = pd.read_csv('resources/mpd to wasabi alignment/mpd_wasabi_aligned.csv', sep='\\t', encoding='utf8')\n",
    "mpd_with_lyrics = mpd_with_lyrics.drop(['Unnamed: 0'], axis=1)\n",
    "mpd_with_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:02:39.380287Z",
     "start_time": "2018-05-23T15:02:38.814639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligned indices    : 416121\n",
      "unique Spotify URIs: 416121\n",
      "unique lyrics      : 358334\n"
     ]
    }
   ],
   "source": [
    "print('aligned indices    :', len(mpd_with_lyrics))\n",
    "print('unique Spotify URIs:', len(set(mpd_with_lyrics['spotify_track_uri'])))\n",
    "print('unique lyrics      :', len(set(mpd_with_lyrics['lyrics'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:02:39.394823Z",
     "start_time": "2018-05-23T15:02:39.383428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (Cactus)<br>What are we waiting for? It&apos;s...\n",
       "1    Don&apos;t blink, they won&apos;t even miss yo...\n",
       "2    Your fingertips across my skin<br>The palm tre...\n",
       "3    I walk along the avenue<br>I never thought I&a...\n",
       "4    I walk along the avenue<br>I never thought I&a...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lyrics = mpd_with_lyrics.head()['lyrics']\n",
    "all_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:02:39.403622Z",
     "start_time": "2018-05-23T15:02:39.397272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       What Are We Waiting For (Life Is Wonderful)\n",
       "1     I'm Made of Wax, Larry, What Are You Made Of?\n",
       "2                               Almost Lover (Live)\n",
       "3                                             I Ran\n",
       "4    I Ran (So Far Away) (Re-Recorded / Remastered)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_titles = mpd_with_lyrics.head()['title']\n",
    "all_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:10:15.521332Z",
     "start_time": "2018-05-23T15:10:15.469817Z"
    }
   },
   "outputs": [],
   "source": [
    "# parse lyrics to segment-line-structure, assuming lines are separated by line_border_indicator and\n",
    "# segments are separated by multiple consecutive line_border_indicator occurences\n",
    "# assuming line_border_indicator is <br> (standard in lyrics.wikia.com)\n",
    "def tree_structure(text):\n",
    "    #normalize segment border encoding\n",
    "    segment_border_encoder = '<segmentborder>'\n",
    "    line_border_encoder = '<lineborder>'\n",
    "    tree_string = re.sub('(( )*<br>( )*){2,}', segment_border_encoder, text)\n",
    "    tree_string = re.sub('( )*<br>( )*', line_border_encoder, tree_string)\n",
    "    #parse tree_string\n",
    "    segment_structure = tree_string.split(segment_border_encoder)\n",
    "    tree_structure = list(map(lambda segment: segment.split(line_border_encoder), segment_structure))\n",
    "    return tree_structure\n",
    "\n",
    "#flattened tree structure, does not differentiate between segment and line border\n",
    "def line_structure(lyric_tree):\n",
    "    return reduce(lambda x, segment: x + segment, lyric_tree, [])\n",
    "\n",
    "# flattened line_structure\n",
    "def token_structure(lyric_tree, tokenizer=word_tokenize):\n",
    "    return reduce(lambda x, line: extend_with_return(x, tokenizer(line)), line_structure(lyric_tree), [])\n",
    "\n",
    "def extend_with_return(some_list, other_list):\n",
    "    some_list.extend(other_list)\n",
    "    return some_list\n",
    "\n",
    "# normalizations we want to apply to all lyrics go here\n",
    "def normalize_lyric(lyric):\n",
    "    lyric = html.unescape(lyric)\n",
    "    lyric = lyric.lower()\n",
    "    return lyric\n",
    "\n",
    "# Reduce a list of numbers to single number / feature (cf. np.average, np.std, ...)\n",
    "def list_span(some_list):\n",
    "    return min(some_list) / max(some_list) if max(some_list) > 0 else 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:13:11.364500Z",
     "start_time": "2018-05-23T15:13:11.141583Z"
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########Stylometric features##########\n",
    "######################################\n",
    "\n",
    "def type_token_ratio(lyric_tokens):\n",
    "    return len(set(lyric_tokens)) / len(lyric_tokens)\n",
    "\n",
    "def line_lengths_in_chars(lyric_lines):\n",
    "    return list(map(len, lyric_lines))\n",
    "\n",
    "def line_lengths_in_tokens(lyric_lines):\n",
    "    return list(map(lambda line: len(word_tokenize(line)), lyric_lines))\n",
    "\n",
    "def pos_tag_distribution(lyric_lines):\n",
    "    # Look at https://spacy.io/api/annotation for a better description of each tag\n",
    "    tags = ['ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', \n",
    "        'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'SPACE']\n",
    "    freq = dict()\n",
    "    for tag in tags:\n",
    "        freq[tag] = 0\n",
    "    for line in lyric_lines:\n",
    "        doc = nlp(line)\n",
    "        for word in doc:\n",
    "            if word.pos_ in tags:\n",
    "                freq[word.pos_] += 1\n",
    "    wc = sum(line_lengths_in_tokens(lyric_lines))\n",
    "    for key in freq:\n",
    "        freq[key] /= wc\n",
    "    return freq\n",
    "\n",
    "def get_rhymes(lyric_lines):\n",
    "    count = 0\n",
    "    for i in range(len(lyric_lines)-1):\n",
    "        words = lyric_lines[i].split()\n",
    "        if len(words) < 1:\n",
    "            continue\n",
    "        rhymes = pronouncing.rhymes(words[-1])\n",
    "        next_line_words = lyric_lines[i+1].split()\n",
    "        if next_line_words is not None and len(next_line_words) > 0 and  next_line_words[-1] in rhymes:\n",
    "            count += 1 \n",
    "    return count / ( len(lyric_lines) if len(lyric_lines) > 0 else 1 )\n",
    "\n",
    "def get_echoisms(lyric_lines):\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    # Do echoism count on a word level\n",
    "    echoism_count = 0\n",
    "    for line in lyric_lines:\n",
    "        doc = nlp(line)\n",
    "        for i in range(len(doc) - 1):\n",
    "            echoism_count += doc[i].text.lower() == doc[i+1].text.lower()\n",
    "        # Count echoisms inside words e.g. yeeeeeeah\n",
    "        for tk in doc:     \n",
    "            for i in range(len(tk.text) - 1):\n",
    "                if tk.text[i] == tk.text[i+1] and tk.text in vowels:\n",
    "                    echoism_count += 1\n",
    "                    break\n",
    "    return echoism_count / sum(line_lengths_in_tokens(lyric_lines))\n",
    "\n",
    "def is_title_in_lyrics(title, lyric_lines):\n",
    "    for line in lyric_lines:\n",
    "        if title in line:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def count_duplicate_lines(lyric_lines):\n",
    "    wc = sum(line_lengths_in_tokens(lyric_lines))\n",
    "    wc = wc if wc > 0 else 1\n",
    "    return sum([lyric_lines.count(x) for x in list(set(lyric_lines)) if lyric_lines.count(x) > 1]) / wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:13:11.722296Z",
     "start_time": "2018-05-23T15:13:11.706629Z"
    }
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "########Segment features##########\n",
    "##################################\n",
    "\n",
    "#The indices of lines that end a segment\n",
    "def segment_borders(lyric_tree):\n",
    "    segment_lengths = reduce(lambda x, block: x + [len(block)], lyric_tree, [])\n",
    "    segment_indices = []\n",
    "    running_sum = -1\n",
    "    for i in range(len(segment_lengths)):\n",
    "        running_sum += segment_lengths[i]\n",
    "        segment_indices.append(running_sum)\n",
    "    return segment_indices[:-1]\n",
    "\n",
    "# lengths of the segments\n",
    "def segment_lengths(lyric_tree):\n",
    "    return reduce(lambda x, block: x + [len(block)], lyric_tree, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:13:12.057160Z",
     "start_time": "2018-05-23T15:13:11.948235Z"
    }
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "########Orientation feature#######\n",
    "##################################\n",
    "def get_verb_tense_frequencies(lyric_lines):\n",
    "    freq = dict()\n",
    "    freq['present'] = 0\n",
    "    freq['future'] = 0\n",
    "    freq['past'] = 0\n",
    "    verbs_no = 0\n",
    "\n",
    "    for line in lyric_lines:\n",
    "        doc = nlp(line)\n",
    "        for i in range(len(doc)):\n",
    "            token = doc[i]\n",
    "            if token.pos_ == 'VERB' and token.tag_ != 'MD': \n",
    "                verbs_no += 1\n",
    "                if 'present' in spacy.explain(token.tag_):\n",
    "                    freq['present'] += 1\n",
    "                elif 'past' in spacy.explain(token.tag_):\n",
    "                    freq['past'] += 1 \n",
    "            elif token.pos_ == 'VERB' and token.tag_ == 'MD' and token.text.lower() == 'will':\n",
    "                if i < len(doc) - 1:\n",
    "                    i += 1\n",
    "                    next_token = doc[i]\n",
    "                    if next_token is not None and next_token.text == 'VB':\n",
    "                        verbs_no += 1\n",
    "                        freq['future'] += 1\n",
    "\n",
    "    if verbs_no > 0:\n",
    "        for key, value in freq.items():\n",
    "            freq[key] = value/verbs_no\n",
    "\n",
    "    return freq\n",
    "\n",
    "def get_polarity_and_subjectivity(lyric_lines):\n",
    "    text = '\\n'.join(lyric_lines)\n",
    "    opinion = TextBlob(text)\n",
    "    sentiment = opinion.sentiment\n",
    "    return (sentiment.polarity, sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:18:23.188927Z",
     "start_time": "2018-05-23T15:18:23.084667Z"
    }
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "########Emotion features##########\n",
    "##################################\n",
    "def get_emotion_vector(lyric, title, modelpath='emodetect.h5'):\n",
    "    model = load_model(modelpath)\n",
    "\n",
    "    lyric_lines = lyric.split('\\n')\n",
    "    \n",
    "    # Featurize lyrics\n",
    "    lyric_doc = nlp(lyric)\n",
    "\n",
    "    sentiment = get_polarity_and_subjectivity(lyric)\n",
    "    verb_freq = get_verb_tense_frequencies(lyric_lines)\n",
    "    pos_tag_freq = pos_tag_distribution(lyric_lines)\n",
    "    \n",
    "    elem = [(\n",
    "        lyric_doc.vector,\n",
    "        get_echoisms(lyric_lines),\n",
    "        count_duplicate_lines(lyric_lines),\n",
    "        is_title_in_lyrics(title, lyric_lines),\n",
    "        verb_freq['present'], verb_freq['past'], verb_freq['future'],\n",
    "        pos_tag_freq['ADJ'], pos_tag_freq['PUNCT'],\n",
    "        sentiment[0], sentiment[1]\n",
    "    )]\n",
    "\n",
    "    columns = ['LYRICS_VECTOR',\n",
    "        'ECHOISMS', \n",
    "        'DUPLICATE_LINES', 'IS_TITLE_IN_LYRICS', 'VERB_PRESENT', \n",
    "        'VERB_PAST', 'VERB_FUTURE', 'ADJ_FREQUENCIES',\n",
    "        'PUNCT_FREQUENCIES',\n",
    "        'SENTIMENT', 'SUBJECTIVITY'\n",
    "    ]\n",
    "    df = pd.DataFrame(data=elem,columns=columns)\n",
    "    \n",
    "    # Turn into numerical features\n",
    "    X_vect = list()\n",
    "    for (i, row) in df.iterrows():\n",
    "        sub_list = list()\n",
    "        for field in row:\n",
    "            if type(field) == str:\n",
    "                field = field[1:-1].split()\n",
    "                sub_list += [float(x.replace('\\n','')) for x in field]\n",
    "            else:\n",
    "                sub_list.append(field)\n",
    "        X_vect.append(np.array(sub_list))\n",
    "    X_vect = np.array(X_vect)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_vect)\n",
    "    X_vect_scaled = sc.transform(X_vect)\n",
    "    \n",
    "    # Return peredictions\n",
    "    return classifier.predict(X_vect_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:19:49.786872Z",
     "start_time": "2018-05-23T15:19:49.593798Z"
    }
   },
   "outputs": [],
   "source": [
    "def representations_from(lyric):\n",
    "    \"\"\"Compute different representations of lyric: tree (with paragraphs), lines, tokens\"\"\"\n",
    "    lyric_tree = tree_structure(lyric)\n",
    "    lyric_lines = line_structure(lyric_tree)\n",
    "    lyric_tokens = token_structure(lyric_tree)\n",
    "    return lyric_tree, lyric_lines, lyric_tokens\n",
    "\n",
    "def feat_vect_from(feature_list):\n",
    "    \"\"\"Assuming a list of features of the lyric\"\"\"\n",
    "    feat_vect = []\n",
    "    feat_vect.append(np.median(feature_list))\n",
    "    feat_vect.append(np.std(feature_list))\n",
    "    feat_vect.append(list_span(feature_list))\n",
    "    return feat_vect\n",
    "\n",
    "def extend_feat_vect(feat_vect, feature_list):\n",
    "    feat_vect.extend(feat_vect_from(feature_list))\n",
    "    return feat_vect\n",
    "\n",
    "def feature_vector_from(lyric, title):\n",
    "    lyric_tree, lyric_lines, lyric_tokens = representations_from(lyric)\n",
    "    \n",
    "    # lump everything in a single feature vector\n",
    "    feat_vect = []\n",
    "    \n",
    "    # segmentation features\n",
    "    feat_vect = extend_feat_vect(feat_vect, segment_lengths(lyric_tree))\n",
    "    \n",
    "    # stylometric features\n",
    "    ln_lengths_chars = line_lengths_in_chars(lyric_lines)\n",
    "    feat_vect = extend_feat_vect(feat_vect, ln_lengths_chars)\n",
    "    feat_vect = extend_feat_vect(feat_vect, line_lengths_in_tokens(lyric_lines))\n",
    "    feat_vect = extend_feat_vect(feat_vect, list(pos_tag_distribution(lyric_lines).values()))\n",
    "    feat_vect = extend_feat_vect(feat_vect, [get_rhymes(lyric_lines)])\n",
    "    feat_vect = extend_feat_vect(feat_vect, [get_echoisms(lyric_lines)])\n",
    "    \n",
    "    # orientation features\n",
    "    feat_vect = extend_feat_vect(feat_vect, list(get_verb_tense_frequencies(lyric_lines).values()))\n",
    "    feat_vect = extend_feat_vect(feat_vect, get_polarity_and_subjectivity(lyric_lines))\n",
    "    \n",
    "    # emotion features\n",
    "    #feat_vect = extend_feat_vect(feat_vect, get_emotion_vector(lyric, title))\n",
    "    \n",
    "    feat_vect.append(len(ln_lengths_chars))\n",
    "    feat_vect.append(type_token_ratio(lyric_tokens))\n",
    "    return feat_vect\n",
    "\n",
    "def feature_vectors_from(many_lyrics: list, many_titles: list) -> np.ndarray:\n",
    "    many_count = len(many_lyrics)\n",
    "    first_feat_vect = feature_vector_from(many_lyrics[0], many_titles[0])\n",
    "    feat_vects = np.empty((many_count, len(first_feat_vect)), dtype=object)\n",
    "    feat_vects[0] = first_feat_vect\n",
    "    for i in range(1, many_count):\n",
    "        feat_vects[i] = feature_vector_from(many_lyrics[i], many_titles[i])\n",
    "    return feat_vects\n",
    "\n",
    "def min_max_scaler(elems: list) -> list:\n",
    "    min_elem = min(elems)\n",
    "    max_elem = max(elems)\n",
    "    min_max_range = max_elem - min_elem\n",
    "    if not min_max_range:\n",
    "        min_max_range = 1\n",
    "    return list(map(lambda x: (x - min_elem) / min_max_range, elems))\n",
    "\n",
    "def apply_to_columns(f, matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply a function f to each column of the matrix\"\"\"\n",
    "    f_matrix = np.empty((matrix.shape[0], matrix.shape[1]))\n",
    "    for j in range(matrix.shape[1]):\n",
    "        f_matrix[:, j] = f(matrix[:, j])\n",
    "    return f_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-23T15:19:50.387Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix = feature_vectors_from(all_lyrics, all_titles)\n",
    "print(matrix)\n",
    "print()\n",
    "\n",
    "scaled_matrix = apply_to_columns(min_max_scaler, matrix)\n",
    "scaled_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
