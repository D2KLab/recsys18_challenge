{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:38:37.794354Z",
     "start_time": "2018-05-27T12:38:26.111096Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "from functools import reduce\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import spacy\n",
    "import pronouncing\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:38:45.742225Z",
     "start_time": "2018-05-27T12:38:37.797085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_track_uri</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>urlSong</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6Z32g3TxhI9KOEDxkF5whx</td>\n",
       "      <td>A Broken Silence</td>\n",
       "      <td>What Are We Waiting For (Life Is Wonderful)</td>\n",
       "      <td>http://lyrics.wikia.com/A_Broken_Silence:What_...</td>\n",
       "      <td>(Cactus)&lt;br&gt;What are we waiting for? It&amp;apos;s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1fTNpl2mxqHVlLqRNbyDhR</td>\n",
       "      <td>A Day To Remember</td>\n",
       "      <td>I'm Made of Wax, Larry, What Are You Made Of?</td>\n",
       "      <td>http://lyrics.wikia.com/A_Day_To_Remember:I%27...</td>\n",
       "      <td>Don&amp;apos;t blink, they won&amp;apos;t even miss yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7BQk0o7TxM3WRFTPCuA4e4</td>\n",
       "      <td>A Fine Frenzy</td>\n",
       "      <td>Almost Lover (Live)</td>\n",
       "      <td>http://lyrics.wikia.com/A_Fine_Frenzy:Almost_L...</td>\n",
       "      <td>Your fingertips across my skin&lt;br&gt;The palm tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33VihH9UNQMxiQS4wcPIKL</td>\n",
       "      <td>A Flock Of Seagulls</td>\n",
       "      <td>I Ran</td>\n",
       "      <td>http://lyrics.wikia.com/A_Flock_Of_Seagulls:I_...</td>\n",
       "      <td>I walk along the avenue&lt;br&gt;I never thought I&amp;a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5VNW7zhvsqo5UD0kUiRTYr</td>\n",
       "      <td>A Flock Of Seagulls</td>\n",
       "      <td>I Ran (So Far Away) (Re-Recorded / Remastered)</td>\n",
       "      <td>http://lyrics.wikia.com/A_Flock_Of_Seagulls:I_...</td>\n",
       "      <td>I walk along the avenue&lt;br&gt;I never thought I&amp;a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        spotify_track_uri               artist  \\\n",
       "0  6Z32g3TxhI9KOEDxkF5whx     A Broken Silence   \n",
       "1  1fTNpl2mxqHVlLqRNbyDhR    A Day To Remember   \n",
       "2  7BQk0o7TxM3WRFTPCuA4e4        A Fine Frenzy   \n",
       "3  33VihH9UNQMxiQS4wcPIKL  A Flock Of Seagulls   \n",
       "4  5VNW7zhvsqo5UD0kUiRTYr  A Flock Of Seagulls   \n",
       "\n",
       "                                            title  \\\n",
       "0     What Are We Waiting For (Life Is Wonderful)   \n",
       "1   I'm Made of Wax, Larry, What Are You Made Of?   \n",
       "2                             Almost Lover (Live)   \n",
       "3                                           I Ran   \n",
       "4  I Ran (So Far Away) (Re-Recorded / Remastered)   \n",
       "\n",
       "                                             urlSong  \\\n",
       "0  http://lyrics.wikia.com/A_Broken_Silence:What_...   \n",
       "1  http://lyrics.wikia.com/A_Day_To_Remember:I%27...   \n",
       "2  http://lyrics.wikia.com/A_Fine_Frenzy:Almost_L...   \n",
       "3  http://lyrics.wikia.com/A_Flock_Of_Seagulls:I_...   \n",
       "4  http://lyrics.wikia.com/A_Flock_Of_Seagulls:I_...   \n",
       "\n",
       "                                              lyrics  \n",
       "0  (Cactus)<br>What are we waiting for? It&apos;s...  \n",
       "1  Don&apos;t blink, they won&apos;t even miss yo...  \n",
       "2  Your fingertips across my skin<br>The palm tre...  \n",
       "3  I walk along the avenue<br>I never thought I&a...  \n",
       "4  I walk along the avenue<br>I never thought I&a...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpd_with_lyrics = pd.read_csv('resources/mpd to wasabi alignment/mpd_wasabi_aligned.csv', sep='\\t', encoding='utf8')\n",
    "mpd_with_lyrics = mpd_with_lyrics.drop(['Unnamed: 0'], axis=1)\n",
    "mpd_with_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:38:46.268149Z",
     "start_time": "2018-05-27T12:38:45.745834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligned indices    : 416121\n",
      "unique Spotify URIs: 416121\n",
      "unique lyrics      : 358334\n"
     ]
    }
   ],
   "source": [
    "print('aligned indices    :', len(mpd_with_lyrics))\n",
    "print('unique Spotify URIs:', len(set(mpd_with_lyrics['spotify_track_uri'])))\n",
    "print('unique lyrics      :', len(set(mpd_with_lyrics['lyrics'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:38:46.283291Z",
     "start_time": "2018-05-27T12:38:46.271832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (Cactus)<br>What are we waiting for? It&apos;s...\n",
       "1    Don&apos;t blink, they won&apos;t even miss yo...\n",
       "2    Your fingertips across my skin<br>The palm tre...\n",
       "3    I walk along the avenue<br>I never thought I&a...\n",
       "4    I walk along the avenue<br>I never thought I&a...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lyrics = mpd_with_lyrics.head()['lyrics']\n",
    "all_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:38:46.294010Z",
     "start_time": "2018-05-27T12:38:46.285947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       What Are We Waiting For (Life Is Wonderful)\n",
       "1     I'm Made of Wax, Larry, What Are You Made Of?\n",
       "2                               Almost Lover (Live)\n",
       "3                                             I Ran\n",
       "4    I Ran (So Far Away) (Re-Recorded / Remastered)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_titles = mpd_with_lyrics.head()['title']\n",
    "all_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:38:46.357152Z",
     "start_time": "2018-05-27T12:38:46.297422Z"
    }
   },
   "outputs": [],
   "source": [
    "# parse lyrics to segment-line-structure, assuming lines are separated by line_border_indicator and\n",
    "# segments are separated by multiple consecutive line_border_indicator occurences\n",
    "# assuming line_border_indicator is <br> (standard in lyrics.wikia.com)\n",
    "def tree_structure(text):\n",
    "    #normalize segment border encoding\n",
    "    segment_border_encoder = '<segmentborder>'\n",
    "    line_border_encoder = '<lineborder>'\n",
    "    tree_string = re.sub('(( )*<br>( )*){2,}', segment_border_encoder, text)\n",
    "    tree_string = re.sub('( )*<br>( )*', line_border_encoder, tree_string)\n",
    "    #parse tree_string\n",
    "    segment_structure = tree_string.split(segment_border_encoder)\n",
    "    tree_structure = list(map(lambda segment: segment.split(line_border_encoder), segment_structure))\n",
    "    return tree_structure\n",
    "\n",
    "#flattened tree structure, does not differentiate between segment and line border\n",
    "def line_structure(lyric_tree):\n",
    "    return reduce(lambda x, segment: x + segment, lyric_tree, [])\n",
    "\n",
    "# flattened line_structure\n",
    "def token_structure(lyric_tree, tokenizer=word_tokenize):\n",
    "    return reduce(lambda x, line: extend_with_return(x, tokenizer(line)), line_structure(lyric_tree), [])\n",
    "\n",
    "def extend_with_return(some_list, other_list):\n",
    "    some_list.extend(other_list)\n",
    "    return some_list\n",
    "\n",
    "# normalizations we want to apply to all lyrics go here\n",
    "def normalize_lyric(lyric):\n",
    "    lyric = html.unescape(lyric)\n",
    "    lyric = lyric.lower()\n",
    "    return lyric\n",
    "\n",
    "# Reduce a list of numbers to single number / feature (cf. np.average, np.std, ...)\n",
    "def list_span(some_list):\n",
    "    return min(some_list) / max(some_list) if max(some_list) > 0 else 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:38:46.572473Z",
     "start_time": "2018-05-27T12:38:46.360071Z"
    }
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "########Stylometric features##########\n",
    "######################################\n",
    "\n",
    "def type_token_ratio(lyric_tokens):\n",
    "    return len(set(lyric_tokens)) / len(lyric_tokens)\n",
    "\n",
    "def line_lengths_in_chars(lyric_lines):\n",
    "    return list(map(len, lyric_lines))\n",
    "\n",
    "def line_lengths_in_tokens(lyric_lines):\n",
    "    return list(map(lambda line: len(word_tokenize(line)), lyric_lines))\n",
    "\n",
    "def pos_tag_distribution(lyric_lines):\n",
    "    # Look at https://spacy.io/api/annotation for a better description of each tag\n",
    "    tags = ['ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', \n",
    "        'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'SPACE']\n",
    "    freq = dict()\n",
    "    for tag in tags:\n",
    "        freq[tag] = 0\n",
    "    for line in lyric_lines:\n",
    "        doc = nlp(line)\n",
    "        for word in doc:\n",
    "            if word.pos_ in tags:\n",
    "                freq[word.pos_] += 1\n",
    "    wc = sum(line_lengths_in_tokens(lyric_lines))\n",
    "    for key in freq:\n",
    "        freq[key] /= wc\n",
    "    return freq\n",
    "\n",
    "def get_rhymes(lyric_lines):\n",
    "    count = 0\n",
    "    for i in range(len(lyric_lines)-1):\n",
    "        words = lyric_lines[i].split()\n",
    "        if len(words) < 1:\n",
    "            continue\n",
    "        rhymes = pronouncing.rhymes(words[-1])\n",
    "        next_line_words = lyric_lines[i+1].split()\n",
    "        if next_line_words is not None and len(next_line_words) > 0 and  next_line_words[-1] in rhymes:\n",
    "            count += 1 \n",
    "    return count / ( len(lyric_lines) if len(lyric_lines) > 0 else 1 )\n",
    "\n",
    "def get_echoisms(lyric_lines):\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    # Do echoism count on a word level\n",
    "    echoism_count = 0\n",
    "    for line in lyric_lines:\n",
    "        doc = nlp(line)\n",
    "        for i in range(len(doc) - 1):\n",
    "            echoism_count += doc[i].text.lower() == doc[i+1].text.lower()\n",
    "        # Count echoisms inside words e.g. yeeeeeeah\n",
    "        for tk in doc:     \n",
    "            for i in range(len(tk.text) - 1):\n",
    "                if tk.text[i] == tk.text[i+1] and tk.text in vowels:\n",
    "                    echoism_count += 1\n",
    "                    break\n",
    "    return echoism_count / sum(line_lengths_in_tokens(lyric_lines))\n",
    "\n",
    "def is_title_in_lyrics(title, lyric_lines):\n",
    "    for line in lyric_lines:\n",
    "        if title in line:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def count_duplicate_lines(lyric_lines):\n",
    "    wc = sum(line_lengths_in_tokens(lyric_lines))\n",
    "    wc = wc if wc > 0 else 1\n",
    "    return sum([lyric_lines.count(x) for x in list(set(lyric_lines)) if lyric_lines.count(x) > 1]) / wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:38:46.593293Z",
     "start_time": "2018-05-27T12:38:46.576352Z"
    }
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "########Segment features##########\n",
    "##################################\n",
    "\n",
    "#The indices of lines that end a segment\n",
    "def segment_borders(lyric_tree):\n",
    "    segment_lengths = reduce(lambda x, block: x + [len(block)], lyric_tree, [])\n",
    "    segment_indices = []\n",
    "    running_sum = -1\n",
    "    for i in range(len(segment_lengths)):\n",
    "        running_sum += segment_lengths[i]\n",
    "        segment_indices.append(running_sum)\n",
    "    return segment_indices[:-1]\n",
    "\n",
    "# lengths of the segments\n",
    "def segment_lengths(lyric_tree):\n",
    "    return reduce(lambda x, block: x + [len(block)], lyric_tree, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:38:46.668896Z",
     "start_time": "2018-05-27T12:38:46.596502Z"
    }
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "########Orientation feature#######\n",
    "##################################\n",
    "def get_verb_tense_frequencies(lyric_lines):\n",
    "    freq = dict()\n",
    "    freq['present'] = 0\n",
    "    freq['future'] = 0\n",
    "    freq['past'] = 0\n",
    "    verbs_no = 0\n",
    "\n",
    "    for line in lyric_lines:\n",
    "        doc = nlp(line)\n",
    "        for i in range(len(doc)):\n",
    "            token = doc[i]\n",
    "            if token.pos_ == 'VERB' and token.tag_ != 'MD': \n",
    "                verbs_no += 1\n",
    "                if 'present' in spacy.explain(token.tag_):\n",
    "                    freq['present'] += 1\n",
    "                elif 'past' in spacy.explain(token.tag_):\n",
    "                    freq['past'] += 1 \n",
    "            elif token.pos_ == 'VERB' and token.tag_ == 'MD' and token.text.lower() == 'will':\n",
    "                if i < len(doc) - 1:\n",
    "                    i += 1\n",
    "                    next_token = doc[i]\n",
    "                    if next_token is not None and next_token.text == 'VB':\n",
    "                        verbs_no += 1\n",
    "                        freq['future'] += 1\n",
    "\n",
    "    if verbs_no > 0:\n",
    "        for key, value in freq.items():\n",
    "            freq[key] = value/verbs_no\n",
    "\n",
    "    return freq\n",
    "\n",
    "def get_polarity_and_subjectivity(lyric_lines):\n",
    "    text = '\\n'.join(lyric_lines)\n",
    "    opinion = TextBlob(text)\n",
    "    sentiment = opinion.sentiment\n",
    "    return (sentiment.polarity, sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:42:58.425290Z",
     "start_time": "2018-05-27T12:42:58.419739Z"
    }
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "########Emotion features##########\n",
    "##################################\n",
    "\n",
    "import emoclassify as clf\n",
    "\n",
    "def get_emotion_vector(lyric, title, modelpath='emodetect.h5'):\n",
    "    return clf.classify(0, '', title, lyric_content = html.unescape(lyric).replace('<br>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:42:59.174051Z",
     "start_time": "2018-05-27T12:42:58.974319Z"
    }
   },
   "outputs": [],
   "source": [
    "def representations_from(lyric):\n",
    "    \"\"\"Compute different representations of lyric: tree (with paragraphs), lines, tokens\"\"\"\n",
    "    lyric_tree = tree_structure(lyric)\n",
    "    lyric_lines = line_structure(lyric_tree)\n",
    "    lyric_tokens = token_structure(lyric_tree)\n",
    "    return lyric_tree, lyric_lines, lyric_tokens\n",
    "\n",
    "def feat_vect_from(feature_list):\n",
    "    \"\"\"Assuming a list of features of the lyric\"\"\"\n",
    "    feat_vect = []\n",
    "    feat_vect.append(np.median(feature_list))\n",
    "    feat_vect.append(np.std(feature_list))\n",
    "    feat_vect.append(list_span(feature_list))\n",
    "    return feat_vect\n",
    "\n",
    "def extend_feat_vect(feat_vect, feature_list):\n",
    "    feat_vect.extend(feat_vect_from(feature_list))\n",
    "    return feat_vect\n",
    "\n",
    "def feature_vector_from(lyric, title):\n",
    "    lyric_tree, lyric_lines, lyric_tokens = representations_from(lyric)\n",
    "    \n",
    "    # lump everything in a single feature vector\n",
    "    feat_vect = []\n",
    "    \n",
    "    # segmentation features\n",
    "    feat_vect = extend_feat_vect(feat_vect, segment_lengths(lyric_tree))\n",
    "    \n",
    "    # stylometric features\n",
    "    ln_lengths_chars = line_lengths_in_chars(lyric_lines)\n",
    "    feat_vect = extend_feat_vect(feat_vect, ln_lengths_chars)\n",
    "    feat_vect = extend_feat_vect(feat_vect, line_lengths_in_tokens(lyric_lines))\n",
    "    feat_vect = extend_feat_vect(feat_vect, list(pos_tag_distribution(lyric_lines).values()))\n",
    "    feat_vect = extend_feat_vect(feat_vect, [get_rhymes(lyric_lines)])\n",
    "    feat_vect = extend_feat_vect(feat_vect, [get_echoisms(lyric_lines)])\n",
    "    \n",
    "    # orientation features\n",
    "    feat_vect = extend_feat_vect(feat_vect, list(get_verb_tense_frequencies(lyric_lines).values()))\n",
    "    feat_vect = extend_feat_vect(feat_vect, get_polarity_and_subjectivity(lyric_lines))\n",
    "    \n",
    "    # emotion features\n",
    "    emo = get_emotion_vector(lyric, title)\n",
    "    feat_vect = extend_feat_vect(feat_vect, get_emotion_vector(lyric, title).reshape(4))\n",
    "    \n",
    "    feat_vect.append(len(ln_lengths_chars))\n",
    "    feat_vect.append(type_token_ratio(lyric_tokens))\n",
    "    return feat_vect\n",
    "\n",
    "def feature_vectors_from(many_lyrics: list, many_titles: list) -> np.ndarray:\n",
    "    many_count = len(many_lyrics)\n",
    "    first_feat_vect = feature_vector_from(many_lyrics[0], many_titles[0])\n",
    "    feat_vects = np.empty((many_count, len(first_feat_vect)), dtype=object)\n",
    "    feat_vects[0] = first_feat_vect\n",
    "    for i in range(1, many_count):\n",
    "        feat_vects[i] = feature_vector_from(many_lyrics[i], many_titles[i])\n",
    "    return feat_vects\n",
    "\n",
    "def min_max_scaler(elems: list) -> list:\n",
    "    min_elem = min(elems)\n",
    "    max_elem = max(elems)\n",
    "    min_max_range = max_elem - min_elem\n",
    "    if not min_max_range:\n",
    "        min_max_range = 1\n",
    "    return list(map(lambda x: (x - min_elem) / min_max_range, elems))\n",
    "\n",
    "def apply_to_columns(f, matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply a function f to each column of the matrix\"\"\"\n",
    "    f_matrix = np.empty((matrix.shape[0], matrix.shape[1]))\n",
    "    for j in range(matrix.shape[1]):\n",
    "        f_matrix[:, j] = f(matrix[:, j])\n",
    "    return f_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T12:43:22.577979Z",
     "start_time": "2018-05-27T12:42:59.513098Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.0 0.44221663871405326 0.6 47.0 18.434890911053575 0.11594202898550725\n",
      "  9.0 4.632242725574456 0.125 0.0136986301369863 0.06072027577139217 0.0\n",
      "  0.03278688524590164 0.0 1.0 0.0 0.0 1e-10 0.1926605504587156\n",
      "  0.21191579375009684 0.0 0.4233585858585859 0.19426767676767678\n",
      "  0.37092157985117347 0.21151292 0.120185494 0.2839179 61\n",
      "  0.3167808219178082]\n",
      " [4.0 1.8652854850741754 0.14285714285714285 29.0 14.56410855583545\n",
      "  0.12698412698412698 9.5 4.621622396850757 0.16666666666666666\n",
      "  0.022530329289428077 0.042523834986257364 0.0 0.0 0.0 1e-10 0.0 0.0\n",
      "  1e-10 0.19318181818181818 0.15773229404285616 0.0 0.09881613756613754\n",
      "  0.24393518518518514 -0.42339456622414334 0.17179891 0.18457119\n",
      "  0.17931825 58 0.2045060658578856]\n",
      " [3.0 2.638181191654584 0.25 29.0 9.160509295642658 0.13636363636363635\n",
      "  6.5 3.186819099387699 0.07142857142857142 0.02865329512893983\n",
      "  0.05108768717321954 0.0 0.0 0.0 1e-10 0.0 0.0 1e-10 0.2631578947368421\n",
      "  0.16100467716884448 0.0 0.18452380952380953 0.1875\n",
      "  -0.007999999999999983 0.13158752 0.29200488 0.010640021 48\n",
      "  0.3495702005730659]\n",
      " [3.0 1.7728105208558367 0.3333333333333333 30.0 7.528432500751225\n",
      "  0.4222222222222222 8.0 2.531435020952764 0.3076923076923077\n",
      "  0.02727272727272727 0.056534294568043084 0.0 0.21428571428571427 0.0\n",
      "  1.0 0.0 0.0 1e-10 0.42857142857142855 0.2208004403689453 0.0\n",
      "  0.40277777777777785 0.2703703703703704 0.1966987620357634 0.19248782\n",
      "  0.22992894 0.0051237065 28 0.37272727272727274]\n",
      " [3.0 1.7728105208558367 0.3333333333333333 30.0 7.528432500751225\n",
      "  0.4222222222222222 8.0 2.531435020952764 0.3076923076923077\n",
      "  0.02727272727272727 0.056534294568043084 0.0 0.21428571428571427 0.0\n",
      "  1.0 0.0 0.0 1e-10 0.42857142857142855 0.2208004403689453 0.0\n",
      "  0.40277777777777785 0.2703703703703704 0.1966987620357634 0.19248782\n",
      "  0.22992894 0.0051237065 28 0.37272727272727274]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.83333333, 1.        , 0.22674419, 0.        ,\n",
       "        1.        , 0.        , 0.15300546, 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.85912624,\n",
       "        0.        , 1.        , 0.08166582, 1.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 0.66742332],\n",
       "       [1.        , 0.64803817, 0.        , 0.        , 0.64509264,\n",
       "        0.03605228, 1.        , 0.99494465, 0.40310078, 0.59056483,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0022096 , 0.        ,\n",
       "        0.        , 0.        , 0.68100559, 0.        , 0.50311154,\n",
       "        0.37472895, 0.62481409, 0.90909091, 0.        ],\n",
       "       [0.        , 1.        , 0.234375  , 0.        , 0.14964315,\n",
       "        0.06667623, 0.        , 0.31196767, 0.        , 1.        ,\n",
       "        0.47063337, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29883041, 0.05188646,\n",
       "        0.        , 0.26408771, 0.        , 0.52295873, 0.        ,\n",
       "        1.        , 0.01978633, 0.60606061, 0.86234154],\n",
       "       [0.        , 0.60592685, 0.41666667, 0.05555556, 0.        ,\n",
       "        1.        , 0.5       , 0.        , 1.        , 0.90768313,\n",
       "        0.76995605, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.        , 0.93658516, 1.        , 0.78066313, 0.76196426,\n",
       "        0.63871396, 0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.60592685, 0.41666667, 0.05555556, 0.        ,\n",
       "        1.        , 0.5       , 0.        , 1.        , 0.90768313,\n",
       "        0.76995605, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.        , 0.93658516, 1.        , 0.78066313, 0.76196426,\n",
       "        0.63871396, 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = feature_vectors_from(all_lyrics, all_titles)\n",
    "print(matrix)\n",
    "print()\n",
    "\n",
    "scaled_matrix = apply_to_columns(min_max_scaler, matrix)\n",
    "scaled_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
